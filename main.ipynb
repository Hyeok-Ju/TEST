{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.graph_loader import load_graph_from_place\n",
    "from module.line_extension import linestring_extension, tunnel_linestring_extension\n",
    "from module.split_road import split_road_and_change_nodes_state\n",
    "from module.generator_node_edge import *\n",
    "from module.cluster import * \n",
    "from module.cluster_spread import *\n",
    "from module.make_map import *\n",
    "\n",
    "from shapely.geometry import MultiLineString, Point\n",
    "from shapely.ops import linemerge\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pydeck as pdk\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HJD = gpd.read_file('./data/extra_data/HangJeongDong_ver20220401.geojson')\n",
    "# main_city = HJD[['sido', 'sidonm']].drop_duplicates().reset_index(drop=True)\n",
    "# main_city = main_city.loc[~main_city['sidonm'].isin(['경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도', '경상북도', '경상남도'])]\n",
    "\n",
    "# main_city_dict = {row['sidonm'][:2]: row['sido'] for _, row in main_city.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HJD = gpd.read_file('./data/extra_data/HangJeongDong_ver20220401.geojson')\n",
    "minor_city = HJD.loc[HJD['sidonm'].isin(['경기도', '강원도', '충청북도', '충청남도', '전라북도', '전라남도', '경상북도', '경상남도'])]\n",
    "\n",
    "minor_city = minor_city[['adm_nm', 'adm_cd']]\n",
    "minor_city['adm_nm'] = [' '.join(i.split(' ')[:2]) for i in minor_city['adm_nm']]\n",
    "minor_city = minor_city.loc[~minor_city['adm_nm'].duplicated()]\n",
    "minor_city = minor_city.reset_index(drop=True)\n",
    "\n",
    "minor_dict = {'경기도 고양시덕양구': '경기도 고양시 덕양구',\n",
    "             '경기도 성남시분당구': '경기도 성남시 분당구',\n",
    "             '경기도 안산시상록구': '경기도 안산시 상록구',\n",
    "             '경기도 고양시일산동구': '경기도 고양시 일산동구',\n",
    "             '경기도 용인시수지구': '경기도 용인시 수지구',\n",
    "             '경기도 수원시영통구': '경기도 수원시 영통구',\n",
    "             '경기도 안산시단원구': '경기도 안산시 단원구',\n",
    "             '경기도 수원시팔달구':'경기도 수원시 팔달구',\n",
    "             '경상남도 창원시마산회원구': '경상남도 창원시 마산회원구',\n",
    "             '경기도 안양시만안구': '경기도 안양시 만안구',\n",
    "             '경상남도 창원시의창구': '경상남도 창원시 의창구',\n",
    "             '경기도 용인시처인구':'경기도 용인시 처인구',\n",
    "             '전라북도 전주시덕진구': '전라북도 전주시 덕진구',\n",
    "             '경상남도 창원시성산구': '경상남도 창원시 성산구',\n",
    "             '경상남도 창원시마산합포구':'경상남도 창원시 마산합포구',\n",
    "             '충청북도 청주시청원구': '충청북도 청주시 청원구',\n",
    "             '경기도 성남시수정구': '경기도 성남시 수정구',\n",
    "             '경기도 용인시기흥구': '경기도 용인시 기흥구',\n",
    "             '경기도 고양시일산서구': '경기도 고양시 일산서구',\n",
    "             '경기도 안양시동안구': '경기도 안양시 동안구',\n",
    "             '충청북도 청주시서원구': '충청북도 청주시 서원구',\n",
    "             '경기도 성남시중원구': '경기도 성남시 중원구',\n",
    "             '충청남도 천안시동남구': '충청남도 천안시 동남구',\n",
    "             '경상북도 포항시북구': '경상북도 포항시 북구',\n",
    "             '충청남도 천안시서북구': '충청남도 천안시 서북구',\n",
    "             '충청북도 청주시흥덕구': '충청북도 청주시 흥덕구',\n",
    "             '경기도 수원시장안구': '경기도 수원시 장안구',\n",
    "             '경기도 수원시권선구': '경기도 수원시 권선구',\n",
    "             '충청북도 청주시상당구': '충청북도 청주시 상당구', \n",
    "             '경상북도 포항시남구': '경상북도 포항시 남구',\n",
    "             '전라북도 전주시완산구': '전라북도 전주시 완산구',\n",
    "             '경상남도 창원시진해구': '경상남도 창원시 진해구'}\n",
    "\n",
    "minor_city['adm_nm'] = [minor_dict[i] if i in minor_dict.keys() else i for i in minor_city['adm_nm']]\n",
    "minor_city['adm_cd'] = [i[:5] for i in minor_city['adm_cd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor_city = minor_city.loc[~minor_city['adm_cd'].isin(os.listdir('./data/result_data/'))]\n",
    "# minor_city = minor_city.tail(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,i in tqdm(minor_city.iterrows()):\n",
    "\n",
    "    place = i['adm_nm']\n",
    "    region_code = i['adm_cd']\n",
    "    \n",
    "    if region_code in os.listdir('./data/result_data/'):\n",
    "        continue\n",
    "    \n",
    "    '''\n",
    "    Step 1. OSMNX을 통한 graph data 로드 \n",
    "    '''\n",
    "    # G1 : 베이스 도시도로, G2 : 자세한 터널을 추가하기 위한 도시도로\n",
    "    G1, G2 = load_graph_from_place(place, region_code)\n",
    "\n",
    "    # 도시도로 추출의 위해 고속도로를 제거했기 때문에 고속도로로 인해 나눠진 도로 다시 연결\n",
    "    road_nodes, road_edges = linestring_extension(G1)\n",
    "    tunnel_nodes, tunnel_edges = tunnel_linestring_extension(G2)\n",
    "\n",
    "    '''\n",
    "    Step 2. main road(간선도로), minor road(집산도로) 분리 후 전처리\n",
    "    '''\n",
    "    # main road-간선도로(주간선, 간선, 보조간선), minor road-집산도로로 분리\n",
    "    main_road, non_main_road = split_road_and_change_nodes_state([road_nodes, road_edges], [tunnel_nodes, tunnel_edges])\n",
    "\n",
    "    ## 자세한 터널 위치를 추가하고 nodes, edges 업데이트 \n",
    "    main_road, non_main_road = generate_tunnel_edges(main_road, non_main_road)\n",
    "\n",
    "    # 터널 양방향으로 나눠진 경우 하나의 터널로 군집\n",
    "    try:\n",
    "        main_road_nodes, main_road_edges = cluster_for_tunnel_1(main_road[0], main_road[1])              # 간선도로 \n",
    "    except:\n",
    "        main_road_nodes, main_road_edges = main_road\n",
    "    try:\n",
    "        non_main_road_nodes, non_main_road_edges = cluster_for_tunnel_1(non_main_road[0], non_main_road[1])  # 집산도로 \n",
    "    except:\n",
    "        non_main_road_nodes, non_main_road_edges = non_main_road\n",
    "\n",
    "    # 간선도로 - 도로 연장 터널 22, 교차로 터널 분류 21\n",
    "    try:\n",
    "        main_road_nodes, main_road_edges = cluster_for_tunnel_2(main_road_nodes, main_road_edges)\n",
    "    except:\n",
    "        pass\n",
    "    '''\n",
    "    Step 3. 복잡한 교차로 군집화\n",
    "    '''\n",
    "    # 간선도로 하나의 교차로에 복잡한 노드가 있는 교차로 하나로 인식하기 위해 군집화\n",
    "    main_road_nodes, main_road_edges = cluster_for_cross(main_road_nodes, main_road_edges)\n",
    "    \n",
    "    '''\n",
    "    Step 4. 도로 분할\n",
    "    '''\n",
    "    ### 간선도로 (도로 교통법에 따른 교차로 150m, 단일로 600m)\n",
    "    # cross segement (meter 150) \n",
    "    main_road_nodes, main_road_edges = generate_cross_nodes_edeges(main_road_nodes, main_road_edges)   \n",
    "    # single way segment (meter 600) \n",
    "    main_road_nodes, main_road_edges = generate_singleway_nodes_edeges(main_road_nodes, main_road_edges)\n",
    "    \n",
    "    # cluster fillna\n",
    "    main_road_nodes.cluster = main_road_nodes.cluster.fillna(9999)\n",
    "    main_road_edges.cluster = main_road_edges.cluster.fillna(9999)\n",
    "    # tunnel fillna \n",
    "    main_road_edges.tunnel = main_road_edges.tunnel.fillna(0)\n",
    "    \n",
    "    # 간선도로 - 150m 공간적 범위 정의\n",
    "    main_road_nodes, main_road_edges = generate_main_road_cluster(main_road_nodes, main_road_edges)\n",
    "    \n",
    "    \n",
    "    ### 집산도로 (간선도로로 나눠진 집산도로를 블럭단위로 군집화)\n",
    "    non_main_road_nodes, non_main_road_edges = generate_non_main_road_cluster(non_main_road_nodes, non_main_road_edges)\n",
    "    try:\n",
    "        non_main_road_edges.cluster = non_main_road_edges.cluster.fillna(-1)\n",
    "    except:\n",
    "        non_main_road_edges['cluster'] = -1\n",
    "    \n",
    "    # cross segement (meter 150)\n",
    "    non_main_road_nodes, non_main_road_edges = generate_cross_nodes_edeges(non_main_road_nodes, non_main_road_edges)   \n",
    "    # single way segment (meter 600) \n",
    "    non_main_road_nodes, non_main_road_edges = generate_singleway_nodes_edeges(non_main_road_nodes, non_main_road_edges) \n",
    "\n",
    "    non_main_road_nodes.connect_inf = non_main_road_nodes.connect_inf.fillna(0)\n",
    "    try:\n",
    "        non_main_road_nodes.cluster = non_main_road_nodes.cluster.fillna(-1)\n",
    "    except:\n",
    "        non_main_road_nodes['cluster'] = -1\n",
    "    '''\n",
    "    Step 5. raw data 저장\n",
    "    '''\n",
    "    ### 미사용 columns 삭제\n",
    "    # edges\n",
    "    main_road_edges = main_road_edges[['u', 'v', 'key', 'highway', 'length', 'geometry', 'tunnel', 'cluster']]\n",
    "    non_main_road_edges = non_main_road_edges[['u', 'v', 'key', 'highway', 'length', 'geometry', 'tunnel', 'cluster', 'M_category']]\n",
    "    # nodes\n",
    "    main_road_nodes = main_road_nodes[['osmid', 'y', 'x', 'geometry', 'state', 'cluster']]\n",
    "    non_main_road_nodes = non_main_road_nodes[['osmid', 'y', 'x', 'geometry', 'state', 'cluster']]\n",
    "    \n",
    "    \n",
    "    # 데이터셋 raw data 저장\n",
    "    if ~(region_code in os.listdir('./data/result_data/')):\n",
    "        os.mkdir(f'./data/result_data/{region_code}')\n",
    "        os.mkdir(f'./data/result_data/{region_code}/raw_data')\n",
    "        os.mkdir(f'./data/result_data/{region_code}/geojson_data')\n",
    "    \n",
    "    \n",
    "    with open(f'./data/result_data/{region_code}/raw_data/main_nodes.pickle', 'wb') as f:\n",
    "        pickle.dump(main_road_nodes, f)\n",
    "\n",
    "    with open(f'./data/result_data/{region_code}/raw_data/main_edges.pickle', 'wb') as f:\n",
    "        pickle.dump(main_road_edges, f)\n",
    "        \n",
    "    with open(f'./data/result_data/{region_code}/raw_data/non_main_nodes.pickle', 'wb') as f:\n",
    "        pickle.dump(non_main_road_nodes, f)\n",
    "\n",
    "    with open(f'./data/result_data/{region_code}/raw_data/non_main_edges.pickle', 'wb') as f:\n",
    "        pickle.dump(non_main_road_edges, f)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    ###### cluster data로 변환\n",
    "    '''\n",
    "    '''\n",
    "    # Main road (간선도로)\n",
    "    '''\n",
    "    # 간선도로에서 연결되어 있지 않은 도로 제거\n",
    "    main_count = pd.DataFrame(main_road_edges[['u','v']].values.reshape(-1)).value_counts()\n",
    "    main_count = pd.DataFrame(main_count, columns=['count']).reset_index()\n",
    "    main_count.columns = ['osmid', 'count']\n",
    "\n",
    "    main_count = {row['osmid']:row['count'] for _,row in  main_count.iterrows()}\n",
    "\n",
    "    main_road_edges = main_road_edges.loc[[False if (main_count[i[0]]==1) & (main_count[i[1]]==1) else True for i in main_road_edges[['u', 'v']].values]]\n",
    "    main_road_nodes = main_road_nodes.loc[main_road_nodes['osmid'].isin(set(main_road_edges[['u','v']].values.reshape(-1)))]\n",
    "    \n",
    "    # 양쪽에 클러스터에 속하는 경우 복제 해주어서, groupby 사용하기 적합하게 데이터 정제\n",
    "    main_road_edges_list = []\n",
    "\n",
    "    for _,row in main_road_edges.iterrows():\n",
    "        if type(row['cluster']) == list:\n",
    "            for i in row['cluster']:\n",
    "                edges = copy.deepcopy(row)\n",
    "                edges['cluster'] = i\n",
    "                main_road_edges_list.append(edges)    \n",
    "        else:\n",
    "            edges = copy.deepcopy(row)\n",
    "            main_road_edges_list.append(edges) \n",
    "\n",
    "    main_road_edges_list = pd.concat(main_road_edges_list,axis=1).T\n",
    "    \n",
    "    \n",
    "    ### 클러스터 재설정\n",
    "    # main_road 단일로\n",
    "    cluster_max = max(main_road_edges_list.loc[main_road_edges_list['cluster'] <  10000]['cluster'])\n",
    "    singleway_count = sum(main_road_edges_list['cluster'] == -1)\n",
    "\n",
    "    # tunnel \n",
    "    tunnel_re_cluster_dict = {i : cluster_max+singleway_count+1+idx  for idx,i in enumerate(set(main_road_edges_list.loc[main_road_edges_list['cluster'] >= 10000]['cluster']))}\n",
    "\n",
    "    main_road_edges_list.loc[main_road_edges_list['cluster'] == -1, 'cluster'] = list(range(int(cluster_max+1), int(cluster_max  + singleway_count+1)))\n",
    "    main_road_edges_list['cluster'] = [tunnel_re_cluster_dict[i] if i >= 10000 else i for i in main_road_edges_list['cluster']]\n",
    "    \n",
    "    ### cluster group\n",
    "    ## intersection\n",
    "    cluster_id_list = []\n",
    "    length_list = []\n",
    "    include_node_list = []\n",
    "    node_count_list = []\n",
    "    tunnel_check_list = [] # 0, 1\n",
    "    type_check_list = []   # single_way, intersection, tunnel\n",
    "    multiline_list = []\n",
    "\n",
    "    node_check_dict = {row['osmid']:row['state'] for _,row in main_road_nodes.iterrows()}\n",
    "\n",
    "    for cluster_id, row in main_road_edges_list[['geometry', 'length', 'cluster', 'u', 'v', 'tunnel']].groupby('cluster'):\n",
    "        \n",
    "        if len(row) >= 2:\n",
    "            cluster_id = cluster_id\n",
    "            length = round(sum(row['length']),2)\n",
    "            include_node = list(set(row[['u','v']].values.reshape(-1)))\n",
    "            node_cnt = sum([1 if node_check_dict[i] == 1 else 0 for i in include_node])\n",
    "            tunnel_check = int(np.any(row['tunnel'].values != 0))\n",
    "            type_check = 'tunnel' if np.all(row['tunnel'].values != 0) else 'intersection'\n",
    "            type_check = 'single_way' if (type_check == 'intersection') & (node_cnt == 0) else type_check\n",
    "            multiline = MultiLineString(row['geometry'].tolist())\n",
    "            multiline = linemerge(multiline) \n",
    "            \n",
    "        else:\n",
    "            cluster_id = cluster_id\n",
    "            length = round(row['length'].astype('float').iloc[0], 2)\n",
    "            include_node = list(set(row[['u','v']].values.reshape(-1)))\n",
    "            node_cnt = sum([1 if node_check_dict[i] == 1 else 0 for i in include_node])\n",
    "            tunnel_check = int(np.any(row['tunnel'].values != 0))\n",
    "            type_check = 'tunnel' if np.all(row['tunnel'].values != 0) else 'single_way' \n",
    "            multiline = row['geometry'].tolist()[0]\n",
    "            \n",
    "        cluster_id_list.append(cluster_id)\n",
    "        length_list.append(length)\n",
    "        include_node_list.append(include_node)   \n",
    "        node_count_list.append(node_cnt)\n",
    "        tunnel_check_list.append(tunnel_check)   \n",
    "        type_check_list.append(type_check)   \n",
    "        multiline_list.append(multiline)\n",
    "        \n",
    "    main_cluster_data = pd.DataFrame(cluster_id_list, columns=['cluster_id'])\n",
    "    main_cluster_data['length'] = length_list\n",
    "    main_cluster_data['node'] = include_node_list\n",
    "    main_cluster_data['node_cnt'] = node_count_list\n",
    "    main_cluster_data['tunnel'] = tunnel_check_list\n",
    "    main_cluster_data['type'] = type_check_list\n",
    "    main_cluster_data['geometry'] = multiline_list\n",
    "    \n",
    "    main_cluster_data = gpd.GeoDataFrame(main_cluster_data, geometry='geometry')\n",
    "\n",
    "    # 중심점 추가\n",
    "    main_cluster_data['centroid_lat'] = [i.centroid.y for i in main_cluster_data['geometry']]\n",
    "    main_cluster_data['centroid_lon'] = [i.centroid.x for i in main_cluster_data['geometry']]\n",
    "\n",
    "    main_cluster_data = main_cluster_data.reset_index(drop=True)\n",
    "\n",
    "    point_df = pd.DataFrame([Point(i[1],i[0]) for i in  main_cluster_data[['centroid_lat', 'centroid_lon']].values], columns=['geometry'])\n",
    "    point_df = gpd.GeoDataFrame(point_df, geometry='geometry')\n",
    "    point_df = gpd.sjoin(point_df, HJD).sort_index()\n",
    "\n",
    "    point_df = point_df[['sgg']]\n",
    "\n",
    "    main_cluster_data['sgg_code'] = point_df['sgg']\n",
    "\n",
    "    main_cluster_data['cluster'] = main_cluster_data['cluster_id']\n",
    "    main_cluster_data['cluster_id'] = [str(i[0])  + str(int(i[1])).zfill(5) for i in  main_cluster_data[['sgg_code', 'cluster_id']].values]\n",
    "    \n",
    "    # columns 정렬 \n",
    "    main_cluster = main_cluster_data[['cluster_id', 'length', 'type', 'sgg_code', 'node', 'node_cnt', 'centroid_lat', 'centroid_lon', 'geometry']]\n",
    "    \n",
    "    ### \n",
    "    ### 단일로만 뽑아서, 20m 버퍼를 주고 겹치는 cluster 동일 cluster로 부여.\n",
    "    main_cluster_singleway = main_cluster.loc[main_cluster['type'] == 'single_way']\n",
    "    main_cluster_geometry = main_cluster_singleway['geometry'] \n",
    "    main_cluster_singleway['geometry'] = main_cluster_singleway['geometry'].centroid\n",
    "\n",
    "    main_cluster_singleway = gpd.GeoDataFrame(main_cluster_singleway, geometry='geometry', crs=4326)\n",
    "\n",
    "    main_cluster_singleway = main_cluster_singleway.to_crs(epsg=5179)\n",
    "    main_cluster_singleway.geometry = main_cluster_singleway.geometry.buffer(20)\n",
    "    main_cluster_singleway = main_cluster_singleway.to_crs(epsg=4326)\n",
    "    \n",
    "    #\n",
    "    test_1 = main_cluster_singleway[['cluster_id', 'geometry']]\n",
    "    test_2 = main_cluster_singleway[['cluster_id', 'geometry']]\n",
    "\n",
    "    test = gpd.sjoin(test_1, test_2)\n",
    "    \n",
    "    # \n",
    "    singleway_re_matching = dict()\n",
    "\n",
    "    for i in test[['cluster_id_left', 'cluster_id_right']].values:\n",
    "        try:\n",
    "            singleway_re_matching[i[0]].append(i[1])\n",
    "        except:\n",
    "            singleway_re_matching[i[0]] = [i[1]] \n",
    "            \n",
    "\n",
    "    main_cluster_singleway['re_cluster'] = [singleway_re_matching[i] for i in main_cluster_singleway['cluster_id']]\n",
    "\n",
    "\n",
    "    for i in main_cluster_singleway[['cluster_id','re_cluster']].values:\n",
    "        try:\n",
    "            main_cluster_singleway.loc[main_cluster_singleway['cluster_id'].isin(i[1]), 'cluster_id'] = i[0]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    main_cluster_singleway['geometry'] = main_cluster_geometry\n",
    "\n",
    "    cluster_id_list = []\n",
    "    length_list = []\n",
    "    include_node_list = []\n",
    "    node_count_list = []\n",
    "    sgg_code_list = []\n",
    "    type_check_list = []   # single_way, intersection, tunnel\n",
    "    multiline_list = []\n",
    "\n",
    "    for id, row in main_cluster_singleway.groupby('cluster_id'):\n",
    "        \n",
    "        if len(row) > 1:\n",
    "            cluster_id = id\n",
    "            length = round(sum(row['length']),2)\n",
    "            include_node = list(set(list(itertools.chain(*row['node'].tolist()))))\n",
    "            node_cnt = sum(row['node_cnt'])\n",
    "            sgg_code = row['sgg_code'].iloc[0]\n",
    "            type_check = 'single_way'\n",
    "            multiline = MultiLineString(list(itertools.chain(*[[j for j in i] if type(i)== MultiLineString else [i] for i in row['geometry']])))\n",
    "            multiline = linemerge(multiline) \n",
    "        else: \n",
    "            cluster_id = id\n",
    "            length = row['length'].iloc[0]\n",
    "            include_node = row['node'].tolist()\n",
    "            node_cnt = row['node_cnt'].iloc[0]\n",
    "            sgg_code = row['sgg_code'].iloc[0]\n",
    "            type_check = 'single_way'\n",
    "            multiline = row['geometry'].iloc[0]\n",
    "        \n",
    "        \n",
    "        cluster_id_list.append(cluster_id)\n",
    "        length_list.append(length)\n",
    "        include_node_list.append(include_node)   \n",
    "        node_count_list.append(node_cnt)  \n",
    "        sgg_code_list.append(sgg_code)\n",
    "        type_check_list.append(type_check)   \n",
    "        multiline_list.append(multiline)\n",
    "        \n",
    "        \n",
    "    main_cluster_singleway = pd.DataFrame(cluster_id_list, columns=['cluster_id'])\n",
    "    main_cluster_singleway['length'] = length_list\n",
    "    main_cluster_singleway['type'] = type_check_list\n",
    "    main_cluster_singleway['sgg_code'] = sgg_code_list\n",
    "    main_cluster_singleway['node'] = include_node_list\n",
    "    main_cluster_singleway['node_cnt'] = node_count_list\n",
    "    main_cluster_singleway['geometry'] = multiline_list\n",
    "\n",
    "    main_cluster_singleway = gpd.GeoDataFrame(main_cluster_singleway, geometry='geometry', crs=4326)\n",
    "\n",
    "    main_cluster_singleway['centroid_lon'] = main_cluster_singleway.centroid.x\n",
    "    main_cluster_singleway['centroid_lat'] = main_cluster_singleway.centroid.y\n",
    "\n",
    "    intersection = main_cluster.loc[main_cluster['type'] != 'single_way']\n",
    "    main_cluster = pd.concat([intersection, main_cluster_singleway])\n",
    "    main_cluster = main_cluster.reset_index(drop=True)\n",
    "    \n",
    "    main_cluster['node'] = [str(i) for i in main_cluster['node']]\n",
    "    \n",
    "    # minor cluster 시작 번호를 주기 위해 cluster max 값 저장\n",
    "    main_cluster_max = max([int(i[5:]) for i in main_cluster['cluster_id']])\n",
    "    \n",
    "    # main road cluster data 저장 \n",
    "    main_cluster.to_file(f'./data/result_data/{region_code}/geojson_data/{region_code}_main_cluster.geojson', driver='GeoJSON')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # Minor road (집산도로)\n",
    "    '''\n",
    "    # 간선도로 사이에 있는 짧은 도로 제거\n",
    "    non_main_road_edges = non_main_road_edges.loc[non_main_road_edges['M_category'] != 9999]\n",
    "    \n",
    "    \n",
    "    # cluster 단위 데이터 생성\n",
    "    cluster_id_list = []\n",
    "    length_list = []\n",
    "    include_node_list = []\n",
    "    node_count_list = []\n",
    "    tunnel_check_list = []\n",
    "    multiline_list = []\n",
    "\n",
    "    node_check_dict = {row['osmid']:row['state'] for _,row in non_main_road_nodes.iterrows()}\n",
    "    \n",
    "    for cluster_id, row in non_main_road_edges[['geometry', 'length', 'M_category', 'u', 'v', 'tunnel']].groupby('M_category'):\n",
    "        \n",
    "        ###\n",
    "        cluster_id = cluster_id\n",
    "        length = round(sum(row['length']),2)\n",
    "        include_node = list(set(row[['u','v']].values.reshape(-1)))\n",
    "        node_cnt = sum([1 if node_check_dict[i] == 1 else 0 for i in include_node])\n",
    "        tunnel_check = int(np.any(row['tunnel'].values != 0))\n",
    "        \n",
    "        multiline = MultiLineString(row['geometry'].tolist())\n",
    "        multiline = linemerge(multiline)\n",
    "        ###\n",
    "        \n",
    "        cluster_id_list.append(cluster_id)\n",
    "        length_list.append(length)\n",
    "        include_node_list.append(include_node)   \n",
    "        node_count_list.append(node_cnt)\n",
    "        tunnel_check_list.append(tunnel_check)\n",
    "        multiline_list.append(multiline)\n",
    "        \n",
    "    non_main_cluster_data = pd.DataFrame(cluster_id_list, columns=['cluster_id'])\n",
    "    non_main_cluster_data['length'] = length_list\n",
    "    non_main_cluster_data['tunnel'] = tunnel_check_list\n",
    "    non_main_cluster_data['node'] = include_node_list\n",
    "    non_main_cluster_data['node_cnt'] = node_count_list\n",
    "    non_main_cluster_data['geometry'] = multiline_list\n",
    "\n",
    "    non_main_cluster_data = gpd.GeoDataFrame(non_main_cluster_data, geometry='geometry')\n",
    "    \n",
    "    # 중심점 추가\n",
    "    non_main_cluster_data['centroid_lat'] = [i.centroid.y for i in non_main_cluster_data['geometry']]\n",
    "    non_main_cluster_data['centroid_lon'] = [i.centroid.x for i in non_main_cluster_data['geometry']]\n",
    "\n",
    "    # cluster 1km 이하인 곳 제거\n",
    "    non_main_cluster_data = non_main_cluster_data.loc[non_main_cluster_data['length'] >= 1000]\n",
    "    non_main_cluster_data = non_main_cluster_data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    point_df = pd.DataFrame([Point(i[1],i[0]) for i in  non_main_cluster_data[['centroid_lat', 'centroid_lon']].values], columns=['geometry'])\n",
    "    point_df = gpd.GeoDataFrame(point_df, geometry='geometry')\n",
    "    point_df = gpd.sjoin(point_df, HJD).sort_index()\n",
    "\n",
    "    point_df = point_df[['sgg']]\n",
    "\n",
    "    non_main_cluster_data['sgg_code'] = point_df['sgg']\n",
    "\n",
    "    # 집산도로 클러스터 이름 재정의\n",
    "    non_main_cluster_dict = {i:main_cluster_max+1+idx for idx,i in enumerate(sorted(set(non_main_cluster_data['cluster_id'])))}\n",
    "    non_main_cluster_data['cluster_id'] = [non_main_cluster_dict[i] for i in non_main_cluster_data['cluster_id']]\n",
    "\n",
    "    non_main_cluster_data['cluster_id'] = [str(i[0])  + str(int(i[1])).zfill(5) for i in  non_main_cluster_data[['sgg_code', 'cluster_id']].values]\n",
    "\n",
    "    # geojson 저장을 위해 node 정보 list 자체를 문자로 변환\n",
    "    non_main_cluster_data['node'] = [str(i) for i in non_main_cluster_data['node']]\n",
    "    \n",
    "    # column 재정렬\n",
    "    non_main_cluster_data = non_main_cluster_data[['cluster_id', 'length', 'sgg_code', 'node', 'node_cnt', 'centroid_lat', 'centroid_lon', 'geometry']]\n",
    "    \n",
    "    non_main_cluster_data.to_file(f'./data/result_data/{region_code}/geojson_data/{region_code}_minor_cluster.geojson', driver='GeoJSON')\n",
    "    \n",
    "\n",
    "\n",
    "    ### cluster 시각화\n",
    "    # 색깔 임의 지정을 위해 랜덤 값 지정\n",
    "    \n",
    "    main_road = main_cluster\n",
    "    minor_road = non_main_cluster_data\n",
    "    \n",
    "    \n",
    "    main_road['r_id'] = np.random.rand(main_road.shape[0]) * 255.0\n",
    "    main_road['g_id'] = np.random.rand(main_road.shape[0]) * 255.0\n",
    "    main_road['b_id'] = np.random.rand(main_road.shape[0]) * 255.0\n",
    "\n",
    "\n",
    "    minor_road['r_id'] = np.random.rand(minor_road.shape[0]) * 255.0\n",
    "    minor_road['g_id'] = np.random.rand(minor_road.shape[0]) * 255.0\n",
    "    minor_road['b_id'] = np.random.rand(minor_road.shape[0]) * 255.0\n",
    "    \n",
    "    minor_road['type'] = 'minor_road'\n",
    "    \n",
    "    try:\n",
    "        place = f'대한민국 {place}'\n",
    "        places = ox.geocode_to_gdf([place])\n",
    "        places = ox.project_gdf(places)\n",
    "        places_centroid = [places['lat'].iloc[0], places['lon'].iloc[0]]\n",
    "    except:\n",
    "        place = ' '.join(place.split(\" \")[::-1])\n",
    "        places = ox.geocode_to_gdf([place])\n",
    "        places = ox.project_gdf(places)\n",
    "        places_centroid = [places['lat'].iloc[0], places['lon'].iloc[0]]\n",
    "    \n",
    "    # 지도 그리기\n",
    "    INITIAL_VIEW_STATE = pdk.ViewState(latitude=places_centroid[0], longitude=places_centroid[1], zoom=10, max_zoom=16, pitch=0, bearing=0)\n",
    "\n",
    "    layer1 = pdk.Layer(\n",
    "        'GeoJsonLayer',\n",
    "        main_road,\n",
    "        id = 'major_road',\n",
    "        pickable=True,\n",
    "        auto_highlight=True,\n",
    "        tooltip=True,\n",
    "        lineWidthScale=10,\n",
    "        getLineWidth=5,\n",
    "        getLineColor = '[r_id, g_id, b_id]',\n",
    "        extruded=True,                 \n",
    "        coverage=1)\n",
    "\n",
    "    layer2 = pdk.Layer(\n",
    "        'GeoJsonLayer',\n",
    "        minor_road,\n",
    "        id = 'minor_road',\n",
    "        pickable=True,\n",
    "        auto_highlight=True,\n",
    "        tooltip=True,\n",
    "        lineWidthScale=10,\n",
    "        getLineWidth=1,\n",
    "        getLineColor = '[r_id, g_id, b_id]',\n",
    "        extruded=True,                 \n",
    "        coverage=1)\n",
    "    \n",
    "    base_map = pdk.Deck(layers=[layer1,layer2], \n",
    "                        tooltip={\n",
    "                            \"html\": \"<b>Cluster ID:</b> {cluster_id} <br/> <b>Number of nodes:</b> {node_cnt} <br/> <b>Type:</b> {type}\"\n",
    "                            },\n",
    "                        initial_view_state=INITIAL_VIEW_STATE)\n",
    "    \n",
    "    \n",
    "    if not('html_data' in os.listdir(f'./data/result_data/{region_code}/')):\n",
    "        os.mkdir(f\"./data/result_data/{region_code}/html_data/\")    \n",
    "    \n",
    "    base_map.to_html(f'./data/result_data/{region_code}/html_data/{region_code}_cluster_map.html')    \n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not('30000' in os.listdir('./data/train_prepared_data/')):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5770bd5bd514e515d9753d06a47129955ceebad56f1a5f2273cb72864838fafa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
